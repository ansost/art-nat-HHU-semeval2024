{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data.\n",
    "df_train = pd.read_pickle(f\"../../data/all_features_with_finetuned_train.pkl\")\n",
    "df_dev = pd.read_pickle(f\"../../data/all_features_with_finetuned_dev.pkl\")\n",
    "df_test = pd.read_pickle(f\"../../data/all_features_with_finetuned_test.pkl\")\n",
    "\n",
    "# get all columns with numeric values (float or int)\n",
    "numeric_cols = [\n",
    "    col for col in df_train.columns if df_train[col].dtype in [\"float64\", \"int64\"]\n",
    "]\n",
    "numeric_cols.remove(\"label\")\n",
    "numeric_cols.remove(\"id\")\n",
    "numeric_cols.remove(\"y_pred_roberta\")\n",
    "\n",
    "# scale all numeric columns\n",
    "for col in numeric_cols:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_train[col].values.reshape(-1, 1))\n",
    "    df_train[col] = scaler.transform(df_train[col].values.reshape(-1, 1))\n",
    "    df_dev[col] = scaler.transform(df_dev[col].values.reshape(-1, 1))\n",
    "    df_test[col] = scaler.transform(df_test[col].values.reshape(-1, 1))\n",
    "\n",
    "# From df_train drop all columns that are not numeric.\n",
    "X_train = df_train.select_dtypes(include=np.number)\n",
    "X_dev = df_dev.select_dtypes(include=np.number)\n",
    "X_test = df_test.select_dtypes(include=np.number)\n",
    "\n",
    "# drop id, text, label if present\n",
    "if \"id\" in X_train.columns:\n",
    "    X_train.drop([\"id\"], axis=1, inplace=True)\n",
    "X_train = X_train.drop([\"label\"], axis=1)\n",
    "if \"id\" in X_dev.columns:\n",
    "    X_dev.drop([\"id\"], axis=1, inplace=True)\n",
    "X_dev = X_dev.drop([\"label\"], axis=1)\n",
    "if \"id\" in df_test.columns:\n",
    "    X_test.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train[\"label\"]\n",
    "y_dev = df_dev[\"label\"]\n",
    "\n",
    "\n",
    "keep = [\n",
    "    \"ratio_ADJ_NOUN\",\n",
    "    \"ratio_VERB_word_count\",\n",
    "    \"ratio_NOUN_word_count\",\n",
    "    \"ratio_ADJ_word_count\",\n",
    "    \"ratio_ADV_word_count\",\n",
    "    \"ratio_PRON_word_count\",\n",
    "    \"ratio_DET_word_count\",\n",
    "    \"ratio_ADP_word_count\",\n",
    "    \"ratio_NUM_word_count\",\n",
    "    \"ratio_CONJ_word_count\",\n",
    "    \"ratio_negative_stem_word_count\",\n",
    "    \"ratio_cefrj_stem_word_count\",\n",
    "    \"ratio_a1_stem_word_count\",\n",
    "    \"ratio_a2_stem_word_count\",\n",
    "    \"ratio_b1_stem_word_count\",\n",
    "    \"ratio_b2_stem_word_count\",\n",
    "    \"ratio_c1_stem_word_count\",\n",
    "    \"ratio_c2_stem_word_count\",\n",
    "    \"mean_log_freq_content_words\",\n",
    "    \"num_freq1_words\",\n",
    "    \"prop_freq_content_words\",\n",
    "    \"prop_unfreq_content_words\",\n",
    "    \"X_pca_0\",\n",
    "    \"X_umap_0\",\n",
    "    \"NEGATIVE\",\n",
    "    \"POSITIVE\",\n",
    "    \"anger\",\n",
    "    \"avg_passive_constructions\",\n",
    "    \"avg_word_length\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"formal\",\n",
    "    \"informal\",\n",
    "    \"joy\",\n",
    "    \"max_depth\",\n",
    "    \"mean_depth\",\n",
    "    \"n_negation_words\",\n",
    "    \"n_punctuation\",\n",
    "    \"n_unique_words\",\n",
    "    \"n_vowels\",\n",
    "    \"n_words\",\n",
    "    \"neutral\",\n",
    "    \"non_toxic\",\n",
    "    \"ratio_top10_content_words\",\n",
    "    \"readability\",\n",
    "    \"sadness\",\n",
    "    \"surprise\",\n",
    "    \"toxic\",\n",
    "    \"verb_noun_ratio\",\n",
    "    \"X_umap_jac_0\",\n",
    "    \"logits_0_roberta\",\n",
    "]\n",
    "\n",
    "# keep only the features in keep = no intercorrelation\n",
    "X_train_keep = X_train[keep]\n",
    "X_dev_keep = X_dev[keep]\n",
    "X_test_keep = X_test[keep]\n",
    "\n",
    "# keep only the features with high correlation with label\n",
    "mydf = df_train.copy()\n",
    "mydf.drop([\"id\"], axis=1, inplace=True)\n",
    "df_corr1 = mydf.corr(method=\"pearson\", numeric_only=True)\n",
    "df_corr1 = df_corr1.round(2)\n",
    "# sort correlations between features and label by absolute value\n",
    "features_label_corr = df_corr1[\"label\"].abs().sort_values(ascending=False)\n",
    "\n",
    "# give feature labels in a list for features with correlation < 0.1\n",
    "low_corr = features_label_corr[features_label_corr < 0.1].index.tolist()\n",
    "\n",
    "# for f in low_corr: remove f from keep\n",
    "keep_high = [x for x in keep if x not in low_corr]\n",
    "\n",
    "# keep only the features in keep_high\n",
    "X_train_keep_high = X_train[keep_high]\n",
    "X_dev_keep_high = X_dev[keep_high]\n",
    "X_test_keep_high = X_test[keep_high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data by roberta prediction\n",
    "bool_rob1 = X_train[\"y_pred_roberta\"] == 1\n",
    "bool_rob0 = X_train[\"y_pred_roberta\"] == 0\n",
    "bool_dev_rob1 = X_dev[\"y_pred_roberta\"] == 1\n",
    "bool_dev_rob0 = X_dev[\"y_pred_roberta\"] == 0\n",
    "bool_test_rob1 = X_test[\"y_pred_roberta\"] == 1\n",
    "bool_test_rob0 = X_test[\"y_pred_roberta\"] == 0\n",
    "\n",
    "X_train1 = X_train_keep_high[bool_rob1]\n",
    "X_train0 = X_train_keep_high[bool_rob0]\n",
    "X_dev1 = X_dev_keep_high[bool_dev_rob1]\n",
    "X_dev0 = X_dev_keep_high[bool_dev_rob0]\n",
    "X_test1 = X_test_keep_high[bool_test_rob1]\n",
    "X_test0 = X_test_keep_high[bool_test_rob0]\n",
    "\n",
    "y_train1 = y_train[bool_rob1]\n",
    "y_train0 = y_train[bool_rob0]\n",
    "y_dev1 = y_dev[bool_dev_rob1]\n",
    "y_dev0 = y_dev[bool_dev_rob0]\n",
    "\n",
    "y_test_id1 = df_test[\"id\"][bool_test_rob1]\n",
    "y_test_id0 = df_test[\"id\"][bool_test_rob0]\n",
    "\n",
    "\n",
    "print(X_train.shape, X_train1.shape, X_train0.shape)\n",
    "print(X_dev.shape, X_dev1.shape, X_dev0.shape)\n",
    "print(X_test.shape, X_test1.shape, X_test0.shape)\n",
    "print()\n",
    "print(y_test_id0[:5], y_test_id1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and dev\n",
    "X_train_dev1 = pd.concat([X_train1, X_dev1])\n",
    "y_train_dev1 = pd.concat([y_train1, y_dev1])\n",
    "X_train_dev0 = pd.concat([X_train0, X_dev0])\n",
    "y_train_dev0 = pd.concat([y_train0, y_dev0])\n",
    "\n",
    "np.random.seed(42)\n",
    "shuffler1 = np.random.permutation(len(X_train_dev1))\n",
    "shuffler0 = np.random.permutation(len(X_train_dev0))\n",
    "X_train_dev1 = X_train_dev1.iloc[shuffler1]\n",
    "y_train_dev1 = y_train_dev1.iloc[shuffler1]\n",
    "X_train_dev0 = X_train_dev0.iloc[shuffler0]\n",
    "y_train_dev0 = y_train_dev0.iloc[shuffler0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save X_train_dev_1 to dataframe\n",
    "# X_train_dev1.to_pickle(\"../../data/submission/X_train_dev1_submission.pkl\")\n",
    "# X_train_dev0.to_pickle(\"../../data/submission/X_train_dev0_submission.pkl\")\n",
    "# X_test1.to_pickle(\"../../data/submission/X_test1_submission.pkl\")\n",
    "# X_test0.to_pickle(\"../../data/submission/X_test0_submission.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier.\n",
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf1 = MLPClassifier(random_state=1, max_iter=300).fit(X_train_dev1, y_train_dev1)\n",
    "clf0 = MLPClassifier(random_state=1, max_iter=300).fit(X_train_dev0, y_train_dev0)\n",
    "\n",
    "y_pred1 = clf1.predict(X_test1)\n",
    "y_pred0 = clf0.predict(X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df1 = pd.DataFrame()\n",
    "subm_df1[\"label\"] = y_pred1\n",
    "subm_df1[\"id\"] = [int(i) for i in y_test_id1]\n",
    "subm_df0 = pd.DataFrame()\n",
    "subm_df0[\"label\"] = y_pred0\n",
    "subm_df0[\"id\"] = [int(i) for i in y_test_id0]\n",
    "submission_df = pd.concat([subm_df1, subm_df0])\n",
    "\n",
    "# Sort by id.\n",
    "submission_df.sort_values(by=[\"id\"], inplace=True)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\n",
    "    \"submission_MLP_standard_noCorr_withFinetuned_two_models.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taskAV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
